//===- GraphFunctionDeviceInfo.h - Utils for setting op devices *- C++ -*-===//
//
// This source file is part of the Swift.org open source project
//
// Copyright (c) 2014 - 2017 Apple Inc. and the Swift project authors
// Licensed under Apache License v2.0 with Runtime Library Exception
//
// See https://swift.org/LICENSE.txt for license information
// See https://swift.org/CONTRIBUTORS.txt for the list of Swift project authors
//
//===----------------------------------------------------------------------===//
//
// This file defines utilities for assigning ops to devices.
//
//===----------------------------------------------------------------------===//

#ifndef SWIFT_SIL_GRAPHFUNCTIONDEVICEINFO_H
#define SWIFT_SIL_GRAPHFUNCTIONDEVICEINFO_H

#include "swift/Basic/LLVM.h"
#include "llvm/ADT/SmallSet.h"
#include "llvm/ADT/StringExtras.h"
#include "llvm/ADT/StringRef.h"

namespace swift {
class ASTContext;
class SILFunction;
struct GraphOperationAttribute;

namespace tf {
class GraphOperationBuilder;
struct GraphOperationInfo;

/// The device type of a tfop instruction (and its output tensors, if any).
enum class DeviceType {
  INVALID,
  CPU,
  GPU,
  TPU,
  /// Indicates this instruction should run on all devices in
  /// `GraphFunctionDeviceInfo::usedDeviceIds`. For example, a promoted
  /// scalar will run on all such devices, in case it is a loop iteration count
  /// and the loop runs on all devices.
  ALL,
};

/// The device id represents a local device, with two components: device type
/// and index. An example is "GPU:3".
// TODO: consider adding a worker (task) component to support remote devices.
struct DeviceId {
  DeviceType type;
  unsigned index;

  /// Map between a DeviceId object and a 64-bit int. The latter is used when we
  /// use DeviceId as the key type of a set/map container.
  // We use 32 bits to encode `type`, which is wasteful.
  uint64_t encode() const { return ((uint64_t)type << 32) | index; }

  static DeviceId decode(uint64_t code) {
    auto type = DeviceType(code >> 32);
    auto index = (unsigned)(code & 0xffffffff);
    return {type, index};
  }

  bool operator==(const DeviceId &rhs) const {
    return type == rhs.type && index == rhs.index;
  }

  bool operator!=(const DeviceId &rhs) const { return !(*this == rhs); }
};

static const char TF_CPU_DEVICE_STRING_PREFIX[] =
    "/job:localhost/replica:0/task:0/device:CPU:";
static const char TF_GPU_DEVICE_STRING_PREFIX[] =
    "/job:localhost/replica:0/task:0/device:GPU:";
// TODO: support multiple TPU cores.
static const char TF_DEFAULT_TPU_DEVICE[] = "TPU_SYSTEM";
// This is a pseudo-device that only exist in the SIL code generated by
// TFPartition and GraphPartitioner, and will be replaced with real devices in
// TFGraphLowering.
static const char TF_ALL_DEVICES[] = "ALL_DEVICES";

static DeviceId AllDeviceId = DeviceId{DeviceType::ALL, (unsigned)-1};

static inline DeviceType _getOpDeviceType(llvm::StringRef device) {
  if (device.startswith(TF_CPU_DEVICE_STRING_PREFIX))
    return DeviceType::CPU;
  if (device.startswith(TF_GPU_DEVICE_STRING_PREFIX))
    return DeviceType::GPU;
  if (device.str() == TF_DEFAULT_TPU_DEVICE)
    return DeviceType::TPU;
  if (device.str() == TF_ALL_DEVICES)
    return DeviceType::ALL;

  // FIXME: Consider also supporting variants of the device string, such as
  // "CPU:0".
  llvm_unreachable("Unknown device type");
}

static inline DeviceId getOpDeviceId(llvm::StringRef device) {
  if (device.startswith(TF_CPU_DEVICE_STRING_PREFIX)) {
    auto deviceIndexStr = device.substr(strlen(TF_CPU_DEVICE_STRING_PREFIX));
    unsigned deviceIndex;
    bool ret = llvm::to_integer(deviceIndexStr, deviceIndex);
    assert(ret && "Invalid device string!");
    return {DeviceType::CPU, deviceIndex};
  }

  return {_getOpDeviceType(device), 0};
}

/// The returned string is compatible with TF device name used in TF graphs.
/// e.g. "/job:localhost/replica:0/task:0/device:GPU:3"
static inline std::string getDeviceString(DeviceId deviceId) {
  switch (deviceId.type) {
  case DeviceType::CPU:
    return TF_CPU_DEVICE_STRING_PREFIX + llvm::utostr(deviceId.index);
  case DeviceType::GPU:
    return TF_GPU_DEVICE_STRING_PREFIX + llvm::utostr(deviceId.index);
  case DeviceType::TPU:
    return TF_DEFAULT_TPU_DEVICE;
  case DeviceType::ALL:
    return TF_ALL_DEVICES;
  case DeviceType::INVALID:
    llvm_unreachable("Unsupported device type");
  }
}

/// This struct holds information about the deviceInfo of the graph we are
/// generating.
struct GraphFunctionDeviceInfo {
  const DeviceId primaryDeviceId;
  const bool isTPUInfeedEnabled;

  using UsedDeviceSet = llvm::SmallSet<uint64_t, 8>;
  const UsedDeviceSet &getUsedDeviceIds() const { return usedDeviceIds; }

  /// Return the deviceInfo for the specified function.
  static GraphFunctionDeviceInfo getForFunction(SILFunction &fn,
                                                bool removeConfigInst);

  /// Whether this is an op that configures the function's device.
  static bool isConfigOp(const GraphOperationInfo &opInfo);

  void markDeviceUsed(DeviceId device) {
    assert(device.type != DeviceType::INVALID);
    if (device.type == DeviceType::ALL ||
        !usedDeviceIds.insert(device.encode()).second)
      return;
  }

  // Choose a device for the graphOpInst under construction and track the chosen
  // device in `usedDeviceIds`.
  //
  // If `opDevice` is already set, respects that device choice. Otherwise,
  // chooses a device based on this deviceInfo and op kernel device
  // availability.
  //
  // `attributes` are a list of GraphOperation level attributes which will
  // eventually be passed to TF_OpSetAttr*. These are used here to determine
  // kernel availability on a device.
  //
  // Returns the chosen device.
  std::string
  handleDevicePlacement(llvm::StringRef opType, llvm::StringRef opDevice,
                        llvm::ArrayRef<GraphOperationAttribute> attributes);

  // Same as above, but adds a "__device" attribute to `opBuilder` instead of
  // returning the device.
  //
  // Caller should avoid adding duplicate device attributes (e.g. calling
  // handleDevicePlacement() multiple times when creating the same graph_op
  // inst). Otherwise SILVerifier will fail on that graph_op inst.
  void
  handleDevicePlacement(llvm::StringRef opType, llvm::StringRef opDevice,
                        ASTContext &ctx, GraphOperationBuilder *opBuilder);

private:
  GraphFunctionDeviceInfo(DeviceId primaryDeviceId, bool isTPUInfeedEnabled)
      : primaryDeviceId(primaryDeviceId),
        isTPUInfeedEnabled(isTPUInfeedEnabled) {
    assert(primaryDeviceId.type != DeviceType::ALL);
    usedDeviceIds.insert(primaryDeviceId.encode());
  }

  // `attributes` are used here to determine kernel availability (primarily
  // dtype constraints).
  DeviceId
  chooseDevice(llvm::StringRef opType,
               llvm::ArrayRef<GraphOperationAttribute> attributes) const;

  // Actual TF devices involved in the tensor computation.
  // It cannot contain DeviceType::ALL.
  UsedDeviceSet usedDeviceIds;
};

} // end namespace tf
} // end namespace swift

#endif
